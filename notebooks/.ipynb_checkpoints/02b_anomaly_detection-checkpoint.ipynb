{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Anomaly Detection Models\n",
    "\n",
    "Training unsupervised anomaly detectors:\n",
    "1. Variational Autoencoder (VAE)\n",
    "2. Isolation Forest\n",
    "3. Local Outlier Factor\n",
    "4. One-Class SVM\n",
    "\n",
    "These will be used as meta-features for the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 797,588 legitimate transactions\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open('../data/processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "# use only legitimate transactions for training\n",
    "X_train_legit = X_train[y_train == 0]\n",
    "print(f\"Training on {len(X_train_legit):,} legitimate transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(32, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(32, latent_dim)\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE...\n",
      "  Epoch 10: loss = 0.0472\n",
      "  Epoch 20: loss = 0.0471\n",
      "  Epoch 30: loss = 0.0471\n"
     ]
    }
   ],
   "source": [
    "def vae_loss(recon, x, mu, logvar, beta=0.5):\n",
    "    recon_loss = nn.functional.mse_loss(recon, x, reduction='mean')\n",
    "    # clamp logvar to prevent numerical instability\n",
    "    logvar = torch.clamp(logvar, min=-10, max=10)\n",
    "    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + beta * kl_loss\n",
    "\n",
    "# scale data for VAE - also clip extreme values\n",
    "vae_scaler = MinMaxScaler()\n",
    "X_train_vae = vae_scaler.fit_transform(X_train_legit)\n",
    "X_test_vae = vae_scaler.transform(X_test)\n",
    "\n",
    "# clip to valid range and handle NaN\n",
    "X_train_vae = np.clip(X_train_vae, 0, 1)\n",
    "X_test_vae = np.clip(X_test_vae, 0, 1)\n",
    "X_train_vae = np.nan_to_num(X_train_vae, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "X_test_vae = np.nan_to_num(X_test_vae, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "# train VAE\n",
    "input_dim = X_train.shape[1]\n",
    "vae = VAE(input_dim, latent_dim=16).to(device)\n",
    "\n",
    "train_tensor = torch.FloatTensor(X_train_vae).to(device)\n",
    "train_loader = DataLoader(TensorDataset(train_tensor), batch_size=512, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"Training VAE...\")\n",
    "vae.train()\n",
    "for epoch in range(30):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x = batch[0]\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = vae(x)\n",
    "        loss = vae_loss(recon, x, mu, logvar)\n",
    "        \n",
    "        # skip if loss is NaN\n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "            \n",
    "        loss.backward()\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"  Epoch {epoch+1}: loss = {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE AUC: 0.5256\n"
     ]
    }
   ],
   "source": [
    "# get anomaly scores (reconstruction error)\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    test_tensor = torch.FloatTensor(X_test_vae).to(device)\n",
    "    recon, _, _ = vae(test_tensor)\n",
    "    vae_scores = ((test_tensor - recon) ** 2).mean(dim=1).cpu().numpy()\n",
    "\n",
    "vae_auc = roc_auc_score(y_test, vae_scores)\n",
    "print(f\"VAE AUC: {vae_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Isolation Forest...\n",
      "Isolation Forest AUC: 0.5676\n"
     ]
    }
   ],
   "source": [
    "# clean data for Isolation Forest\n",
    "X_train_legit_clean = np.nan_to_num(X_train_legit, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_test_iso = np.nan_to_num(X_test, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    contamination=0.01,  # expected fraud rate\n",
    "    max_samples=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Isolation Forest...\")\n",
    "iso_forest.fit(X_train_legit_clean)\n",
    "\n",
    "# scores: more negative = more anomalous\n",
    "iso_scores = -iso_forest.score_samples(X_test_iso)\n",
    "iso_auc = roc_auc_score(y_test, iso_scores)\n",
    "print(f\"Isolation Forest AUC: {iso_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LOF on 50,000 samples...\n",
      "LOF AUC: 0.6976\n"
     ]
    }
   ],
   "source": [
    "# LOF is slow on large data, so we sample\n",
    "sample_size = min(50000, len(X_train_legit))\n",
    "np.random.seed(42)\n",
    "sample_idx = np.random.choice(len(X_train_legit), sample_size, replace=False)\n",
    "X_lof_train = X_train_legit[sample_idx]\n",
    "\n",
    "# handle NaN/Inf values\n",
    "X_lof_train = np.nan_to_num(X_lof_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_test_clean = np.nan_to_num(X_test, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination=0.01,\n",
    "    novelty=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Training LOF on {sample_size:,} samples...\")\n",
    "lof.fit(X_lof_train)\n",
    "\n",
    "lof_scores = -lof.score_samples(X_test_clean)\n",
    "lof_auc = roc_auc_score(y_test, lof_scores)\n",
    "print(f\"LOF AUC: {lof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training OCSVM on 50,000 samples...\n",
      "OCSVM AUC: 0.5466\n"
     ]
    }
   ],
   "source": [
    "# OCSVM also needs sampling\n",
    "ocsvm = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    nu=0.01\n",
    ")\n",
    "\n",
    "print(f\"Training OCSVM on {sample_size:,} samples...\")\n",
    "ocsvm.fit(X_lof_train)  # reuse LOF sample (already cleaned)\n",
    "\n",
    "ocsvm_scores = -ocsvm.score_samples(X_test_clean)\n",
    "ocsvm_auc = roc_auc_score(y_test, ocsvm_scores)\n",
    "print(f\"OCSVM AUC: {ocsvm_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ANOMALY DETECTION RESULTS\n",
      "==================================================\n",
      "VAE:              AUC = 0.5256\n",
      "Isolation Forest: AUC = 0.5676\n",
      "LOF:              AUC = 0.6976\n",
      "One-Class SVM:    AUC = 0.5466\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANOMALY DETECTION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"VAE:              AUC = {vae_auc:.4f}\")\n",
    "print(f\"Isolation Forest: AUC = {iso_auc:.4f}\")\n",
    "print(f\"LOF:              AUC = {lof_auc:.4f}\")\n",
    "print(f\"One-Class SVM:    AUC = {ocsvm_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models saved to ../models/\n"
     ]
    }
   ],
   "source": [
    "# save models and scores\n",
    "anomaly_data = {\n",
    "    'scores': {\n",
    "        'vae': vae_scores,\n",
    "        'isolation_forest': iso_scores,\n",
    "        'lof': lof_scores,\n",
    "        'ocsvm': ocsvm_scores\n",
    "    },\n",
    "    'auc': {\n",
    "        'vae': vae_auc,\n",
    "        'isolation_forest': iso_auc,\n",
    "        'lof': lof_auc,\n",
    "        'ocsvm': ocsvm_auc\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../models/anomaly_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(anomaly_data, f)\n",
    "\n",
    "# save individual models\n",
    "torch.save(vae.state_dict(), '../models/vae.pt')\n",
    "joblib.dump(iso_forest, '../models/isolation_forest.pkl')\n",
    "joblib.dump(lof, '../models/lof.pkl')\n",
    "joblib.dump(ocsvm, '../models/ocsvm.pkl')\n",
    "\n",
    "print(\"\\nModels saved to ../models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Anomaly detection models trained on legitimate transactions:\n",
    "- Isolation Forest shows best standalone AUC\n",
    "- All scores will be used as meta-features in ensemble\n",
    "\n",
    "**Next:** Fraud technique analysis in notebook 02c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
